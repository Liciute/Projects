{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google Play and Apple Store markets apps analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of this project is to put into work my new knowledge of Python coding and at the same time create a valuable data analytics project that could provide insights to applications developers about what kind of free english apps are more likely to attract users. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a vast amount of applications in Google Play and Apple Store markets.  As of September 2018, there were approximately 2 million iOS apps available on the App Store, and 2.1 million Android apps on Google Play. Obviously, all of them can not be equally popular and profitable. The goal of this project is to highlight trends among most succesfull applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reach the goal above free open source data was obtained from two different sources to provide information about apps on two major application markets: Google Play(2018) and Apple Store(2017).<br> - Google Play apps sample of around 10 000 apps information was obtained [here](https://www.kaggle.com/lava18/google-play-store-apps).<br> - Apple Store apps sample of over 7000 apps data was downloaded [here](https://www.kaggle.com/ramamet4/app-store-apple-data-set-10k-apps)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opening and Exploring the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to start working with the new data we, first, have to import a csv reader and assign the dataset to a variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing reader to open the datasets\n",
    "from csv import reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading datasets\n",
    "# reading Google Play data, calling it list and asigning it to a variable 'android'. The dataset has a header so we separate it from the rest of the data and asign it to varibale 'android_header'.\n",
    "opened_file = open('googleplaystore.csv')\n",
    "read_file = reader(opened_file)\n",
    "android = list(read_file)\n",
    "android_header = android[0]\n",
    "android = android[1:]\n",
    "\n",
    "# repeating the same actions with Apple Store data, just asigning it to a variable called 'ios' and it´s header to variable 'ios_header'. \n",
    "opened_file = open('AppleStore.csv')\n",
    "read_file = reader(opened_file)\n",
    "ios = list(read_file)\n",
    "ios_header = ios[0]\n",
    "ios = ios[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are creating a function 'explore_data' to have a quick overview of datasets, like few rows and also a number of columns and number of rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_data(dataset, start, end, rows_and_columns=False):\n",
    "    dataset_slice = dataset[start:end]    \n",
    "    for row in dataset_slice:\n",
    "        print(row)\n",
    "        print('\\n') # adds a new (empty) line between rows\n",
    "        \n",
    "    if rows_and_columns:\n",
    "        print('Total number of rows:', len(dataset))\n",
    "        print('Total number of columns:', len(dataset[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets explore the data and compare the datasets itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Android apps dataset Header\n",
      "['App', 'Category', 'Rating', 'Reviews', 'Size', 'Installs', 'Type', 'Price', 'Content Rating', 'Genres', 'Last Updated', 'Current Ver', 'Android Ver']\n",
      "\n",
      "\n",
      "Android apps dataset first data row\n",
      "['Photo Editor & Candy Camera & Grid & ScrapBook', 'ART_AND_DESIGN', '4.1', '159', '19M', '10,000+', 'Free', '0', 'Everyone', 'Art & Design', 'January 7, 2018', '1.0.0', '4.0.3 and up']\n",
      "\n",
      "\n",
      "Total number of rows: 10841\n",
      "Total number of columns: 13\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "IOS apps dataset Header\n",
      "['id', 'track_name', 'size_bytes', 'currency', 'price', 'rating_count_tot', 'rating_count_ver', 'user_rating', 'user_rating_ver', 'ver', 'cont_rating', 'prime_genre', 'sup_devices.num', 'ipadSc_urls.num', 'lang.num', 'vpp_lic']\n",
      "\n",
      "\n",
      "IOS apps dataset first data row\n",
      "['284882215', 'Facebook', '389879808', 'USD', '0.0', '2974676', '212', '3.5', '3.5', '95.0', '4+', 'Social Networking', '37', '1', '29', '1']\n",
      "\n",
      "\n",
      "Total number of rows: 7197\n",
      "Total number of columns: 16\n"
     ]
    }
   ],
   "source": [
    "print('Android apps dataset Header')\n",
    "print(android_header)\n",
    "print('\\n')\n",
    "print('Android apps dataset first data row')\n",
    "explore_data(android, 0, 1, True)\n",
    "print('\\n')\n",
    "print('\\n')\n",
    "print('IOS apps dataset Header')\n",
    "print(ios_header)\n",
    "print('\\n')\n",
    "print('IOS apps dataset first data row')\n",
    "explore_data(ios, 0, 1, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the data extracted above, despite some of the data are similar, the datasets are not organized the same way. We have 3 more data columns in IOS dataset, nevertheless the columns does not match if we compare headers. Thus, we have to be careful to run the comparisons. Even if we create finctions, loops that can be suitable for both datasets, we have to make sure we use the right indexes,for example, app name is index 0 for android dataset, while it´s index 1 for IOS. Nevertheless, in order to make this data more comparable and also to make sure all the data within data sets are relevant (there are no duplicates, no wrong data) we will perform data set cleaning, see more in the next chapter. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning and modifying datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deleting false rows\n",
    "On the website where the data was obtained, we found a [comment pointing out](https://www.kaggle.com/lava18/google-play-store-apps/discussion/66015), that within android data line with index 10472 was false. In order to investigate this fact we will print the headline of android data, the first line for comparison, and the line number 10472 to see if the latter line is false."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['App', 'Category', 'Rating', 'Reviews', 'Size', 'Installs', 'Type', 'Price', 'Content Rating', 'Genres', 'Last Updated', 'Current Ver', 'Android Ver']\n",
      "\n",
      "\n",
      "['Photo Editor & Candy Camera & Grid & ScrapBook', 'ART_AND_DESIGN', '4.1', '159', '19M', '10,000+', 'Free', '0', 'Everyone', 'Art & Design', 'January 7, 2018', '1.0.0', '4.0.3 and up']\n",
      "\n",
      "\n",
      "['Life Made WI-Fi Touchscreen Photo Frame', '1.9', '19', '3.0M', '1,000+', 'Free', '0', 'Everyone', '', 'February 11, 2018', '1.0.19', '4.0 and up']\n"
     ]
    }
   ],
   "source": [
    "print(android_header)\n",
    "print('\\n')\n",
    "print(android[0])\n",
    "print('\\n')\n",
    "print(android[10472])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that indeed, data on the list android[10472] is not maching the header, as  'Catergory' supposed to be a string like on the first line 'ART_AND_DESIGN', but instead it´s a float '1.9', the rest of the values looks missplaced accordingly. As we have enough of data, we are not gonna figure out how this particular faulty list should actually look like and we just going to go forward with deleting it by using deletetion function (see below). To make sure the row is successfully deleted we are going to run the length count of android list of list before the deletion and after.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10841\n",
      "10840\n"
     ]
    }
   ],
   "source": [
    "print(len(android))\n",
    "del(android[10472])\n",
    "print(len(android))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There were no comments about false/ missing data on IOS dataset, thus, actions above are not necessary to repeat with IOS data. We move on with clearing the duplicates. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking for duplicates\n",
    "Common problem in large datasets is duplicates. That means that there are more or less identical rows, throughut the dataset. To make sure there are no duplicates we have to create a function that collects duplicates, so we could delete it and have dataset combined only from unique rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_data_android = [] # creating an empty list to gather the names of the apps that reoccures in android data set\n",
    "unique_data_android = [] # creating an empty list to gather all the different app names taht we can find in android data set\n",
    "\n",
    "for row in android:\n",
    "    app_name = row[0] # we know that app names are stored in the very first column of android list of lists\n",
    "    if app_name in unique_data_android:\n",
    "        duplicate_data_android.append(app_name) # if the name already occured in the unique app names list we count this value into the list of duplicate data\n",
    "    else:\n",
    "        unique_data_android.append(app_name) # and if the name was not yet meet in the data set we will add it to the list of unique app names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let see if there are any duplicates by counting the length of duplicate_data_android."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1181\n"
     ]
    }
   ],
   "source": [
    "print(len(duplicate_data_android))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, what a surprise! we found 1181 duplicates within a datset. That´s quite a few. Now we should investigate and try to understand why there are duplicates if possible, before we get rid of them. We don´t know yet whether the duplicates are identical or identical is just the app name but the values that are following are actually different. First, lets find a first duplicattion example and compare all the data that has the same app name. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quick PDF Scanner + OCR FREE\n"
     ]
    }
   ],
   "source": [
    "print(duplicate_data_android[0]) #printing the first line from the newly created list of duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we gonna loop through all the data of android datset and print out all the rows with app name 'Quick PDF Scanner + OCR FREE' to compare it in between. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['App', 'Category', 'Rating', 'Reviews', 'Size', 'Installs', 'Type', 'Price', 'Content Rating', 'Genres', 'Last Updated', 'Current Ver', 'Android Ver']\n",
      "\n",
      "\n",
      "['Quick PDF Scanner + OCR FREE', 'BUSINESS', '4.2', '80805', 'Varies with device', '5,000,000+', 'Free', '0', 'Everyone', 'Business', 'February 26, 2018', 'Varies with device', '4.0.3 and up']\n",
      "['Quick PDF Scanner + OCR FREE', 'BUSINESS', '4.2', '80805', 'Varies with device', '5,000,000+', 'Free', '0', 'Everyone', 'Business', 'February 26, 2018', 'Varies with device', '4.0.3 and up']\n",
      "['Quick PDF Scanner + OCR FREE', 'BUSINESS', '4.2', '80804', 'Varies with device', '5,000,000+', 'Free', '0', 'Everyone', 'Business', 'February 26, 2018', 'Varies with device', '4.0.3 and up']\n"
     ]
    }
   ],
   "source": [
    "print(android_header) # we will also print the header so we can understand what each value stands for\n",
    "print('\\n')\n",
    "for row in android:\n",
    "    app_name = row[0]\n",
    "    if app_name == 'Quick PDF Scanner + OCR FREE':\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the comparison above, the only difference we can find is on the fourth column called 'Size', it provides the number of total reviews submited for the app. It is logical to assume, that all the rows are correct, however, obtained information on different timings, thus the  row with the highest number of reviews (4th column) should be most reliable with latest data about the app. Now printing all the duplicates and manualy picking the latest data about the app is not a great idea as we saw we have over 1000 duplicates to review. We have to come up with a smarter and faster way to clean our data, but before that let´s see if there are any duplicates in IOS data before we move on with cleaning Android dataset duplicates.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum of two lists above: 7197\n",
      "actual ios dataset sum of rows: 7197\n"
     ]
    }
   ],
   "source": [
    "duplicate_data_ios = []\n",
    "unique_data_ios = []\n",
    "\n",
    "for row in ios:\n",
    "    app_name = row[1]\n",
    "    if app_name not in unique_data_ios: # previously we used in command, this is an alternative, just filling up the lists from the other end\n",
    "        unique_data_ios.append(app_name)\n",
    "    else:\n",
    "        duplicate_data_ios.append(app_name)\n",
    "\n",
    "print('sum of two lists above:', len(duplicate_data_ios) + len(unique_data_ios))\n",
    "print('actual ios dataset sum of rows:', len(ios))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see above the lengths are the same, so that means in further sections about cleaning data from duplicates we will work only with Android dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we are going to go forward with creating a dictionary for unique data with highest number of reviews (in case of duplicates). That is necessary not only to see if our assumption is correct, but also it will be used in cleaning the data from duplictaes later on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_max = {}\n",
    "for row in android:\n",
    "    app_name = row[0]\n",
    "    total_reviews = row[3]\n",
    "    if app_name in reviews_max and reviews_max[app_name] < total_reviews:\n",
    "        reviews_max[app_name] = total_reviews\n",
    "    elif app_name not in reviews_max:\n",
    "        reviews_max[app_name] = total_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we are right the length of this dictionary above should match the difference of android data set length and number of duplicates. Lets see:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of unique data: 9659\n",
      "Lenght of apps with highest reviews numbers: 9659\n"
     ]
    }
   ],
   "source": [
    "print('Amount of unique data:', len(android) - len(duplicate_data_android))\n",
    "print('Lenght of apps with highest reviews numbers:', len(reviews_max))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, we confirmed we are on the right track, but that´s not yet it. We have to create two new lists to divide the data to either android_cleaned (no duplicates), or already_added that will store only app names so we could keep recognising the duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "android_clean = [] # our actual cleaned dataset for analysis cleared of duplicates\n",
    "already_added = [] # just let us keep track of unique data we have already added\n",
    "for row in android:\n",
    "    app_name = row[0]\n",
    "    total_reviews = row[3]\n",
    "    if total_reviews == reviews_max[app_name] and app_name not in already_added:\n",
    "        android_clean.append(row)\n",
    "        already_added.append(app_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To confirm that our code worked and we have created succesfully a new list called android_clean with all unique data, we will run once again the length command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Photo Editor & Candy Camera & Grid & ScrapBook', 'ART_AND_DESIGN', '4.1', '159', '19M', '10,000+', 'Free', '0', 'Everyone', 'Art & Design', 'January 7, 2018', '1.0.0', '4.0.3 and up']\n",
      "\n",
      "\n",
      "Total number of rows: 9659\n",
      "Total number of columns: 13\n"
     ]
    }
   ],
   "source": [
    "explore_data(android_clean, 0, 1, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The numbers match. That means we are done with clearing the duplicates, we have to keep in mind that for further work we have to use list of lists calles 'android_clean', not just 'android'. An alternative is just to reasign 'android_clean' to 'android', so we do not forget which dataset to use, but I will keep it as it is, so it is easier to follow what has been done to the dataset. </p> Our data is not yet ready for analysis, there´s one more step we want to do. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning from unecessary data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes we won´t consider all the correct data in the data set as useful. For instance, our datasets combine thousands of apps from all around the world in several languages (see example below), however, we want to analyse only those available in English. We are going to attempt to clean the dataset from apps in languages that we don´t understand and focus on apps that are available for broader English speaking world population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "爱奇艺PPS -《欢乐颂2》电视剧热播\n",
      "Wowkwis aq Ka'qaquj\n"
     ]
    }
   ],
   "source": [
    "print(ios[813][1])\n",
    "print(android_clean[4412][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, there´s no inbuilt command to recognize the language of the app from the dataset, nevertheless, our datasets do not have a column with such information. No worries, we can find our way around it. By following [ASCII](https://en.wikipedia.org/wiki/ASCII) coding standard, we know that each letter, symbol has a corresponding number, and English alphabet letters corresponds to numbers from 0 to 127 (uppercase counts like a separate symbol). It is very important not to forget to get well familiar with your dataset because only assuming things will make you write incorrect code or simply lose data. in this occasion, I have reviewed and noticed that there are english apps that uses some symbols in their title (emojies for example) that won´t be recognised as english alphabet of course. To avoid losing date we are going to use a special code that demands at least three characters to be of an English alphabet in order to pass through. For this code we will create a function for name characters also afterwards use loops and if commands to return an improved dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def english_app(string): #crating a function that return false(for english app) in case three or more characters in the string is not from traditional english alphabet\n",
    "    non_english_alphabet_character = 0 \n",
    "    \n",
    "    for character in string:\n",
    "        if ord(character) > 127:\n",
    "            non_english_alphabet_character += 1\n",
    "    \n",
    "    if non_english_alphabet_character > 3:\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "android_english = [] # creating new list for newest android dataset\n",
    "\n",
    "for row in android_clean:\n",
    "    app_name = row[0]\n",
    "    if english_app(app_name):\n",
    "        android_english.append(row)\n",
    "\n",
    "ios_english = [] # creating new list for newest Apple store dataset\n",
    "\n",
    "for row in ios:\n",
    "    app_name = row[1] # remember the app name is placed in a different column on this data set\n",
    "    if english_app(app_name):\n",
    "        ios_english.append(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now see few lines of each dataset to see if the code worked well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Photo Editor & Candy Camera & Grid & ScrapBook', 'ART_AND_DESIGN', '4.1', '159', '19M', '10,000+', 'Free', '0', 'Everyone', 'Art & Design', 'January 7, 2018', '1.0.0', '4.0.3 and up']\n",
      "\n",
      "\n",
      "['U Launcher Lite – FREE Live Cool Themes, Hide Apps', 'ART_AND_DESIGN', '4.7', '87510', '8.7M', '5,000,000+', 'Free', '0', 'Everyone', 'Art & Design', 'August 1, 2018', '1.2.4', '4.0.3 and up']\n",
      "\n",
      "\n",
      "['Sketch - Draw & Paint', 'ART_AND_DESIGN', '4.5', '215644', '25M', '50,000,000+', 'Free', '0', 'Teen', 'Art & Design', 'June 8, 2018', 'Varies with device', '4.2 and up']\n",
      "\n",
      "\n",
      "Total number of rows: 9614\n",
      "Total number of columns: 13\n",
      "\n",
      "\n",
      "['284882215', 'Facebook', '389879808', 'USD', '0.0', '2974676', '212', '3.5', '3.5', '95.0', '4+', 'Social Networking', '37', '1', '29', '1']\n",
      "\n",
      "\n",
      "['389801252', 'Instagram', '113954816', 'USD', '0.0', '2161558', '1289', '4.5', '4.0', '10.23', '12+', 'Photo & Video', '37', '0', '29', '1']\n",
      "\n",
      "\n",
      "['529479190', 'Clash of Clans', '116476928', 'USD', '0.0', '2130805', '579', '4.5', '4.5', '9.24.12', '9+', 'Games', '38', '5', '18', '1']\n",
      "\n",
      "\n",
      "Total number of rows: 6183\n",
      "Total number of columns: 16\n"
     ]
    }
   ],
   "source": [
    "explore_data(android_english, 0, 3, True)\n",
    "print('\\n')\n",
    "explore_data(ios_english, 0, 3, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore date output looks fine, no red flags so far, we don´t see mixed, false data, duplicates or non English apps so far also, the total number of apps in each data set have shrunked what means the code has succesfully eliminated the some suspicious data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Focusing on free apps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will once again create a new list of lists that will meet our needs better. This time we want to get only data of free apps for the further analysis. As both datasets have a price of apps included in it this part is relatively easy. In the end we will once again see the length of the dataset to see if the amount of rows has changed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of free apps in english on Google play store:\n",
      "8862\n",
      "\n",
      "\n",
      "Total of free apps in english on Apple play store:\n",
      "3222\n"
     ]
    }
   ],
   "source": [
    "android_english_free = []\n",
    "\n",
    "for row in android_english:\n",
    "    price = row[7]\n",
    "    if price == '0':\n",
    "        android_english_free.append(row)\n",
    "        \n",
    "print('Total of free apps in english on Google play store:')\n",
    "print(len(android_english_free))\n",
    "print('\\n')\n",
    "\n",
    "ios_english_free = []\n",
    "\n",
    "for row in ios_english:\n",
    "    price = row[4]\n",
    "    if price == '0.0':\n",
    "        ios_english_free.append(row)\n",
    "        \n",
    "print('Total of free apps in english on Apple play store:')\n",
    "print(len(ios_english_free))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apps popularity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now as our app data is pretty clean  and ready for analysis we can start performing some funtions to draw valued conclusions. My very first question is, what genre of free apps ar most popular in both IOS and Android  stores? To find out that we will have to write a code to create a dictionary with genre types and count their frequency, and create another function that could make the first dictionary more readable and display data in descending order. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_table(dataset, variable_index):\n",
    "    table = {}\n",
    "    total = 0\n",
    "    \n",
    "    for row in dataset:\n",
    "        total += 1 # we will need this total to count the percentage, that is basically the total number of rows in the dataset\n",
    "        genre = row[variable_index]\n",
    "        \n",
    "        if genre in table:\n",
    "            table[genre] += 1\n",
    "        else:\n",
    "            table[genre] = 1\n",
    "           \n",
    "    freq_table_percent = {}\n",
    "    for key in table:\n",
    "        freq_table_percent[key] = round((table[key]/total)*100)\n",
    "\n",
    "    return freq_table_percent #at first we creted  frequence dictionary for different genres and then we created a second part in the function to calculate the percentage showing what percent of the total apps number is certain genre.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That´s not it yet. having a clear table might not be the easiest way to compare apps genre in case of wider range of genre variety. Thus, we should organize the data in descending order. Unfortunately, we can not just sort the dictionary, actually we can but it won´t display everything we want, only the keys in the right order, so if we want to see the percentages next to the sorted keys we have to create another function to convert dictionary to tuple and then sort it. See below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_table(dataset, variable_index):\n",
    "    table_display = []\n",
    "    table = freq_table(dataset, variable_index)\n",
    "    for key in table:\n",
    "        key_value_as_tuple = (table[key], key)\n",
    "        table_display.append(key_value_as_tuple)\n",
    "        \n",
    "    table_sorted_descending = sorted(table_display, reverse = True)\n",
    "# the rule to create tuples is first to write the value then the key, we are not used to see data this way, thus we gonna add up a little change below to print data in traditional manner:\n",
    "        \n",
    "    for entry in table_sorted_descending:\n",
    "        print(entry[1], ':', entry[0], '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let´s see how did it go:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Android apps frequence table for genre:\n",
      "FAMILY : 19 %\n",
      "GAME : 10 %\n",
      "TOOLS : 8 %\n",
      "BUSINESS : 5 %\n",
      "PRODUCTIVITY : 4 %\n",
      "MEDICAL : 4 %\n",
      "LIFESTYLE : 4 %\n",
      "FINANCE : 4 %\n",
      "SPORTS : 3 %\n",
      "SOCIAL : 3 %\n",
      "PHOTOGRAPHY : 3 %\n",
      "PERSONALIZATION : 3 %\n",
      "NEWS_AND_MAGAZINES : 3 %\n",
      "HEALTH_AND_FITNESS : 3 %\n",
      "COMMUNICATION : 3 %\n",
      "VIDEO_PLAYERS : 2 %\n",
      "TRAVEL_AND_LOCAL : 2 %\n",
      "SHOPPING : 2 %\n",
      "DATING : 2 %\n",
      "BOOKS_AND_REFERENCE : 2 %\n",
      "WEATHER : 1 %\n",
      "PARENTING : 1 %\n",
      "MAPS_AND_NAVIGATION : 1 %\n",
      "LIBRARIES_AND_DEMO : 1 %\n",
      "HOUSE_AND_HOME : 1 %\n",
      "FOOD_AND_DRINK : 1 %\n",
      "EVENTS : 1 %\n",
      "ENTERTAINMENT : 1 %\n",
      "EDUCATION : 1 %\n",
      "COMICS : 1 %\n",
      "BEAUTY : 1 %\n",
      "AUTO_AND_VEHICLES : 1 %\n",
      "ART_AND_DESIGN : 1 %\n"
     ]
    }
   ],
   "source": [
    "print('Android apps frequence table for genre:')\n",
    "display_table(android_english_free, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since I am too lazy to count the number of different categories I created a simple function n_categories to do that for me. See it below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_categories(dataset, index):\n",
    "    unique_categories = []\n",
    "    total = 0\n",
    "    \n",
    "    for row in dataset:\n",
    "        category = row[index]\n",
    "        \n",
    "        if category not in unique_categories:\n",
    "            unique_categories.append(category)\n",
    "            total += 1\n",
    "            \n",
    "    return print('Total number of unique categories:', total)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of unique categories: 33\n"
     ]
    }
   ],
   "source": [
    "n_categories(android_english_free, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IOS apps frequency data for genre:\n",
      "Games : 58 %\n",
      "Entertainment : 8 %\n",
      "Photo & Video : 5 %\n",
      "Education : 4 %\n",
      "Utilities : 3 %\n",
      "Social Networking : 3 %\n",
      "Shopping : 3 %\n",
      "Sports : 2 %\n",
      "Productivity : 2 %\n",
      "Music : 2 %\n",
      "Lifestyle : 2 %\n",
      "Health & Fitness : 2 %\n",
      "Weather : 1 %\n",
      "Travel : 1 %\n",
      "Reference : 1 %\n",
      "News : 1 %\n",
      "Food & Drink : 1 %\n",
      "Finance : 1 %\n",
      "Business : 1 %\n",
      "Navigation : 0 %\n",
      "Medical : 0 %\n",
      "Catalogs : 0 %\n",
      "Book : 0 %\n"
     ]
    }
   ],
   "source": [
    "print('IOS apps frequency data for genre:')\n",
    "display_table(ios_english_free, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of unique categories: 23\n"
     ]
    }
   ],
   "source": [
    "n_categories(ios_english_free,11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well we can see this is a pretty interesting results, as numbers differ quite a bit between the two appstores. Of course we have to keep in mind that the cathegories are not alike either, android dataset has 10 genre categories more than IOS dataset. Anyhow, we can see that the most of the IOS apps are games apps (58%) or suitable for other kind of entertainment (+8%), while the significant part of android apps are aiming to please families´ needs (19%), also there´s a high level of games apps (10%) and practical apps that are considered as tools (8%)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case of looking for  a type of free english app to create, it looks like entertaining game, suitable for families could be a good way to go to succeed in both apps stores. However, let´s not forget that the frequency we have recently obtained does not say that these are the most popular apps, it only point out that there are significant amounts of these type of apps in apps stores, what could also mean there´s the largest competition. To get a better view we have to get more statistics about other variables.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counting total instals for different app genres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks smart to get an average number of instals for different genre for both appstores to see if our hypotheses above is on track. As for this computing we will manipulate the data inside the list, we have to double ckeck if the data contained is in a right format and can be used for average count. From the function explore data, that we already used couple of times above we can see that install vallues has some characters like commas and + signs, what will make (ex. '10,000+'), that won´t work in counting the average, thus, we will have to remove it. That´s alright, there is an easy way to do so, we will just add couple of lines to our code, I will highlight it with a comment.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ART_AND_DESIGN average installs per app of this category:  1986335.0\n",
      "AUTO_AND_VEHICLES average installs per app of this category:  1196411.0\n",
      "BEAUTY average installs per app of this category:  1007803.0\n",
      "BOOKS_AND_REFERENCE average installs per app of this category:  4867493.0\n",
      "BUSINESS average installs per app of this category:  3239904.0\n",
      "COMICS average installs per app of this category:  3082057.0\n",
      "COMMUNICATION average installs per app of this category:  12058499.0\n",
      "DATING average installs per app of this category:  10632004.0\n",
      "EDUCATION average installs per app of this category:  9977448.0\n",
      "ENTERTAINMENT average installs per app of this category:  10072651.0\n",
      "EVENTS average installs per app of this category:  9673036.0\n",
      "FINANCE average installs per app of this category:  8224426.0\n",
      "FOOD_AND_DRINK average installs per app of this category:  7875509.0\n",
      "HEALTH_AND_FITNESS average installs per app of this category:  7429973.0\n",
      "HOUSE_AND_HOME average installs per app of this category:  7239071.0\n",
      "LIBRARIES_AND_DEMO average installs per app of this category:  7012219.0\n",
      "LIFESTYLE average installs per app of this category:  6313652.0\n",
      "GAME average installs per app of this category:  8507973.0\n",
      "FAMILY average installs per app of this category:  6983363.0\n",
      "MEDICAL average installs per app of this category:  6601692.0\n",
      "SOCIAL average installs per app of this category:  7273923.0\n",
      "SHOPPING average installs per app of this category:  7266119.0\n",
      "PHOTOGRAPHY average installs per app of this category:  7702341.0\n",
      "SPORTS average installs per app of this category:  7517208.0\n",
      "TRAVEL_AND_LOCAL average installs per app of this category:  7713662.0\n",
      "TOOLS average installs per app of this category:  8007661.0\n",
      "PERSONALIZATION average installs per app of this category:  7902657.0\n",
      "PRODUCTIVITY average installs per app of this category:  8276372.0\n",
      "PARENTING average installs per app of this category:  8222067.0\n",
      "WEATHER average installs per app of this category:  8195242.0\n",
      "VIDEO_PLAYERS average installs per app of this category:  8504864.0\n",
      "NEWS_AND_MAGAZINES average installs per app of this category:  8534503.0\n",
      "MAPS_AND_NAVIGATION average installs per app of this category:  8471852.0\n"
     ]
    }
   ],
   "source": [
    "categories_android = freq_table(android_english_free,1)\n",
    "installs_total = 0 \n",
    "len_category = 0\n",
    "for category in categories_android:\n",
    "    for app in android_english_free:\n",
    "        category_app = app[1]\n",
    "        if category == category_app:\n",
    "            n_installs = app[5]\n",
    "            n_installs = n_installs.replace('+', '') # removing + character from the value in order to be able to use value fr calculations\n",
    "            n_installs = n_installs. replace(',', '') # removing comma from the value to be able to make average calculations\n",
    "            installs_total += float(n_installs) # making sure the type of value is suitable for calculations\n",
    "            len_category += 1\n",
    "    avg_installs = round(installs_total/len_category, 0)\n",
    "    print(category, 'average installs per app of this category: ', avg_installs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately,this data is not too trustworthy as values were not precise, let´s see again the possible values below.  all the install numbers are rounded and 16% of all the numbers ar just pointed as more than a million what can vary up to 4, 999, 999 installs per app. But is the best data we have so let´s try to use it the best we can."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,000,000+ : 16 %\n",
      "100,000+ : 12 %\n",
      "10,000,000+ : 11 %\n",
      "10,000+ : 10 %\n",
      "1,000+ : 8 %\n",
      "5,000,000+ : 7 %\n",
      "100+ : 7 %\n",
      "500,000+ : 6 %\n",
      "50,000+ : 5 %\n",
      "5,000+ : 5 %\n",
      "10+ : 4 %\n",
      "500+ : 3 %\n",
      "50,000,000+ : 2 %\n",
      "50+ : 2 %\n",
      "100,000,000+ : 2 %\n",
      "5+ : 1 %\n",
      "1+ : 1 %\n",
      "500,000,000+ : 0 %\n",
      "1,000,000,000+ : 0 %\n",
      "0+ : 0 %\n",
      "0 : 0 %\n"
     ]
    }
   ],
   "source": [
    "display_table(android_english_free, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our top categories Family and Games have high numbes of installs (both have over 5mln installs), however I know that every tenth android app of some sort has more than 10mln instals. Well I know it´s only an avarege, but I want to know what is most comnon genre of the apps that has been installed for over 10mln times. I´ll do this before I analyse IOS data to see which approach I like better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most popular genre among most downloaded apps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we gonna create a new list with apps that has 10 mln instals or more and see what is a most popular genre among them using the function we have created earlier (display table)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1343\n"
     ]
    }
   ],
   "source": [
    "android_most_instals = []\n",
    "\n",
    "for row in android_english_free:\n",
    "    n_instals = row[5]\n",
    "    if n_instals == '10,000,000+' or n_instals == '50,000,000+' or n_instals == '100,000,000+' or n_installs == '500,000,000+' or n_instals == '1,000,000,000+':\n",
    "        android_most_instals.append(row)\n",
    "\n",
    "print(len(android_most_instals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAME : 21 %\n",
      "FAMILY : 14 %\n",
      "TOOLS : 10 %\n",
      "PHOTOGRAPHY : 7 %\n",
      "PRODUCTIVITY : 5 %\n",
      "COMMUNICATION : 5 %\n",
      "SHOPPING : 4 %\n",
      "VIDEO_PLAYERS : 3 %\n",
      "SPORTS : 3 %\n",
      "SOCIAL : 3 %\n",
      "PERSONALIZATION : 3 %\n",
      "TRAVEL_AND_LOCAL : 2 %\n",
      "NEWS_AND_MAGAZINES : 2 %\n",
      "LIFESTYLE : 2 %\n",
      "HEALTH_AND_FITNESS : 2 %\n",
      "ENTERTAINMENT : 2 %\n",
      "BOOKS_AND_REFERENCE : 2 %\n",
      "WEATHER : 1 %\n",
      "MAPS_AND_NAVIGATION : 1 %\n",
      "FOOD_AND_DRINK : 1 %\n",
      "FINANCE : 1 %\n",
      "EDUCATION : 1 %\n",
      "DATING : 1 %\n",
      "BUSINESS : 1 %\n",
      "PARENTING : 0 %\n",
      "LIBRARIES_AND_DEMO : 0 %\n",
      "HOUSE_AND_HOME : 0 %\n",
      "COMICS : 0 %\n",
      "BEAUTY : 0 %\n",
      "AUTO_AND_VEHICLES : 0 %\n",
      "ART_AND_DESIGN : 0 %\n"
     ]
    }
   ],
   "source": [
    "display_table(android_most_instals, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that we proved that the most popular apps on Android  is mainly games or tools or oriented to support famillies (what usually is still game). I am not gonna repeat these steps with IOS data, just because it didn´t reveal any new hypothesis, just supported the one made earlier. Nevertheless, IOS data had event a more significant freqency distribution, what should also remain among the most instaled apps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite we can see significant differences between Google play and Apple Store in scope and some numbers of the most popular genre of apps. There is one tendency that could improve the chances of newly created English app to be downloaded - it has to be entertaining and fun or at least practical. In case that´s a game , the one that can include the whole family or simply multiple players that can be using their own devices is a good way to go. Just think of it, mobile phones are so often used while trying to make time go faster, while commuting, traveling, waiting  for something or someone or simply when having nothing else to do. So the main goal is to be entertained, if the app suggest a possibility to be entertained and do this in connection with people you care that can be even more entertaining and plus, encaurages people to 'recruite' new users on their own. If that sounds like too complicated or the market too competing because of number of apps in it, there is an option B what is  practicalityies. People love when phones solves their everyday problems, we don´t like carrying  everythign with ourselves, and if possible we want our phones to save us from struggles or unexpected situations, such apps for example are those that can measure the room by only using the app and your camera, a digital compas, weather forecast apps or period calendar.   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
